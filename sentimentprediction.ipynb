{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import re \n",
    "import pickle \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "df= pd.read_csv('train_preprocess.tsv', sep='\\t', header=None)\n",
    "df.columns =['text', 'label']\n",
    "\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_unnecessary_char(text):\n",
    "    text = re.sub('\\n',' ',text) # Remove every '\\n'\n",
    "    text = re.sub('rt',' ',text) # Remove every retweet symbol\n",
    "    text = re.sub('user',' ',text) # Remove every username\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text) # Remove every URL\n",
    "    text = re.sub('  +', ' ', text) # Remove extra spaces\n",
    "    return text\n",
    "    \n",
    "def remove_nonaplhanumeric(text):\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
    "    return text\n",
    "\n",
    "def preprocess(text):\n",
    "    text = lowercase(text) # 1\n",
    "    text = remove_nonaplhanumeric(text) # 2\n",
    "    text = remove_unnecessary_char(text) # 3\n",
    "    return text\n",
    "\n",
    "df['text_clean'] = df.text.apply(preprocess)\n",
    "\n",
    "neg = df.loc[df['label'] == 'negative'].text_clean.tolist()\n",
    "neu = df.loc[df['label'] == 'neutral'].text_clean.tolist()\n",
    "pos = df.loc[df['label'] == 'positive'].text_clean.tolist()\n",
    "\n",
    "neg_label = df.loc[df['label'] == 'negative'].label.tolist()\n",
    "neu_label = df.loc[df['label'] == 'neutral'].label.tolist()\n",
    "pos_label = df.loc[df['label'] == 'positive'].label.tolist()\n",
    "\n",
    "total_data = pos + neu + neg\n",
    "labels = pos_label + neu_label + neg_label\n",
    "\n",
    "max_features = 100000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ', lower=True)\n",
    "tokenizer.fit_on_texts(total_data)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(total_data)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "maxlen = max(len(x) for x in X)\n",
    "\n",
    "X = pad_sequences(X)\n",
    "Y = pd.get_dummies(labels)\n",
    "Y = Y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "embed_dim = 100\n",
    "units = 64\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n",
    "# model.add(LSTM(units, dropout=0.2))\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "# model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "# print(model.summary())\n",
    "\n",
    "# adam = optimizers.Adam(learning_rate = 0.001)\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "# history = model.fit(X_train, y_train, epochs=10, batch_size=10, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# predictions = model.predict(X_test)\n",
    "# y_pred = predictions\n",
    "# matrix_test = metrics.classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "input_text = \"\"\" \n",
    "beta sedang berjuang melawan kanker\n",
    "\"\"\"\n",
    "\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "model = load_model('modellstm.h5')\n",
    "\n",
    "\n",
    "\n",
    "def sentiment_text(input_text, model):\n",
    "    if(model ==\"lstm\"):\n",
    "        model = load_model('modellstm.h5')\n",
    "    elif(model == \"nn\"):\n",
    "        model = load_model('modelRNN.h5')\n",
    "\n",
    "    text = [preprocess(input_text)]\n",
    "    predicted = tokenizer.texts_to_sequences(text)\n",
    "    guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "    prediction = model.predict(guess)\n",
    "    print(prediction[0])\n",
    "    polarity = np.argmax(prediction[0])\n",
    "\n",
    "    print('Prediction: ',prediction)\n",
    "    print('Polarity :',polarity)\n",
    "    print('Text: ',text[0])\n",
    "    print('Sentiment: ',sentiment[polarity])\n",
    "\n",
    "    return sentiment[polarity]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sentiment_file(file, model):\n",
    "    if(model ==\"lstm\"):\n",
    "        model = load_model('modellstm.h5')\n",
    "    elif(model == \"nn\"):\n",
    "        model = load_model('modelRNN.h5')\n",
    "    first_column = file.iloc[:, 0]\n",
    "    file = first_column.astype(\"string\").apply(preprocess)\n",
    "    print(\"======== finish preprocess =========\")\n",
    "\n",
    "    file = file.to_frame()\n",
    "    if(isinstance(file, pd.DataFrame)):\n",
    "        file.rename(columns={ file.columns[0]: \"Tweet\" }, inplace = True)\n",
    "        file[\"Sentiment\"] = None\n",
    "        file['Tweet'] = file['Tweet'].astype('string')\n",
    "        file['Sentiment'] = file['Sentiment'].astype('string')\n",
    "\n",
    "        for i in range(len(file)):\n",
    "            text = file['Tweet'][i]\n",
    "            text = [text]\n",
    "\n",
    "            predicted = tokenizer.texts_to_sequences(text)\n",
    "            guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "            prediction = model.predict(guess)\n",
    "\n",
    "            polarity = np.argmax(prediction[0])\n",
    "\n",
    "            file[\"Sentiment\"][i] =  sentiment[polarity]\n",
    "\n",
    "        print(\"======== FINISH TEST =========\")\n",
    "        return file\n",
    "    else:\n",
    "        print(\"======== FAILED TEST =========\")\n",
    "        return \"File is Unreadable\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9a0684188baa8478e4aab5739f9a6ca9e6188f8492b9b67656bb38dc99a20e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
